{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f19756",
   "metadata": {
    "id": "21f19756"
   },
   "source": [
    "# Bulk RNA-Seq: Cohort Selection and Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55162adc",
   "metadata": {
    "id": "55162adc"
   },
   "source": [
    "This notebook demonstrates how to use the **Genestack ODM API** to access and explore bulk RNA-seq data stored in an ODM instance. It explains how to configure the API connection, retrieve metadata and data for selected entities, and interpret the returned results in a reproducible, programmable way.\n",
    "The notebook is organized into three main parts:\n",
    "* **Prerequisites** – loads the required Python libraries and helper functions. This section can be minimized when running the notebook end-to-end if all dependencies are already installed.\n",
    "* **ODM API Configuration** – an interactive setup for establishing a secure connection to your ODM instance using an API token.\n",
    "* **Working with Data** – examples of typical ODM API endpoints for metadata and data retrieval (including multi-omics), with explanations of the API response structure and its relevance for downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d204d",
   "metadata": {
    "id": "120d204d"
   },
   "source": [
    "## 1. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfbb008",
   "metadata": {
    "id": "2dfbb008"
   },
   "source": [
    "Before running the notebook, make sure your environment is ready. You will need Python 3.10+ and `pip`. Install all dependencies with:\n",
    "```\n",
    "pip install odm-sdk numpy pandas matplotlib seaborn scipy ipywidgets ipykernel requests\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9ccd4",
   "metadata": {
    "id": "1ba9ccd4"
   },
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bae7ce",
   "metadata": {
    "id": "c1bae7ce"
   },
   "outputs": [],
   "source": [
    "# standard library (come with Python)\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from getpass import getpass\n",
    "from io import StringIO\n",
    "\n",
    "# third-party (need installation)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import requests\n",
    "import odm_api\n",
    "\n",
    "# set default matplotlib style\n",
    "plt.style.use('default')\n",
    "\n",
    "# set warnings to ignore FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b59466",
   "metadata": {
    "id": "32b59466"
   },
   "source": [
    "### 1.2 Functions\n",
    "\n",
    "This section defines utility functions used across the notebook to streamline interaction with the ODM API and to support visualization of retrieved data. Collecting them here keeps the workflow sections concise and focused on analysis rather than implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13665f56",
   "metadata": {
    "id": "13665f56"
   },
   "outputs": [],
   "source": [
    "def set_api_credentials(odm_url, api_prefix='/api/v1'):\n",
    "    \"\"\"\n",
    "    Set ODM API credentials interactively, using getpass or fallback to widget-based UI.\n",
    "\n",
    "    Attempts to use `getpass` to prompt for an API token (works in terminal environments).\n",
    "    If that fails (e.g., in JupyterLab or web-based notebooks), it falls back to a widget-based input form.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    odm_url : str\n",
    "        The ODM server URL, e.g. 'https://q001-demo.trial.genestack.com/'\n",
    "    api_prefix : str, optional\n",
    "        The API endpoint prefix (default is '/api/v1').\n",
    "\n",
    "    Sets global variables\n",
    "    ------------\n",
    "        odm_base_url : str\n",
    "            The base ODM API URL with prefix.\n",
    "        token : str\n",
    "            The provided API authentication token.\n",
    "    \"\"\"\n",
    "    # ensure API prefix is provided with the URL\n",
    "    if not re.search(r'/api.+', odm_url):\n",
    "        base_url = odm_url + api_prefix\n",
    "\n",
    "    try:\n",
    "        # enter token via getpass (works in terminal-based environments)\n",
    "        global odm_base_url, token\n",
    "        token = getpass(\"Auth Token: \")\n",
    "        odm_base_url = base_url\n",
    "\n",
    "    except (EOFError, OSError):\n",
    "        # fallback to widget-based input (works in web environments)\n",
    "        set_api_credentials_ui(base_url)\n",
    "\n",
    "\n",
    "def set_api_credentials_ui(base_url):\n",
    "    \"\"\"\n",
    "    Displays widgets for ODM API server and token selection.\n",
    "\n",
    "    Args:\n",
    "        base_url (str, optional): Default server URL for ODM with API prefix (e.g. /api/v1).\n",
    "        If not provided, uses 'ODM_BASE_URL' env variable or default.\n",
    "    \"\"\"\n",
    "    odm_base_url_widget = widgets.Text(\n",
    "        value=base_url if base_url is not None else os.getenv('ODM_BASE_URL', ''),\n",
    "        description='Base URL:',\n",
    "        layout=widgets.Layout(width='600px')\n",
    "    )\n",
    "    token_widget = widgets.Password(\n",
    "        value=os.getenv('ODM_API_TOKEN', ''),\n",
    "        description='Auth Token:',\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    set_button = widgets.Button(description='Set Credentials', button_style='primary')\n",
    "    status_html = widgets.HTML()\n",
    "\n",
    "    def _set_credentials(_):\n",
    "        global odm_base_url, token\n",
    "        odm_base_url = odm_base_url_widget.value.strip()\n",
    "        token = token_widget.value.strip()\n",
    "        masked = ('***' if not token else (token[:4] + '…' + token[-4:] if len(token) >= 8 else '***'))\n",
    "        status_html.value = f\"<span style='color: green;'>Credentials set. Token: {masked}</span>\"\n",
    "\n",
    "    set_button.on_click(_set_credentials)\n",
    "    display(widgets.VBox([odm_base_url_widget, token_widget, set_button, status_html]))\n",
    "\n",
    "\n",
    "def plot_grouped_violin(\n",
    "    combined_data,\n",
    "    group_by='Disease',\n",
    "    preferred=None,\n",
    "    log1p=True,\n",
    "    figsize_scale=0.6,\n",
    "    min_figsize=12,\n",
    "    height=6\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot grouped violin + strip plot, optionally log1p of expression,\n",
    "    grouped by an inferred or specified metadata column.\n",
    "\n",
    "    Parameters:\n",
    "        combined_data (pd.DataFrame): DataFrame with expression data and sample metadata.\n",
    "        group_by (str): Initial column to try as grouping variable (default: 'Disease').\n",
    "        preferred (list): Optional list of preferred columns to scan as grouping variables.\n",
    "        log1p (bool): Whether to plot log1p(expression). Default: True.\n",
    "        figsize_scale (float): Scale for figure width by number of genes.\n",
    "        min_figsize (int): Minimum figure width.\n",
    "        height (float): Figure height.\n",
    "    \"\"\"\n",
    "\n",
    "    sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "\n",
    "    plot_df = combined_data.copy()\n",
    "\n",
    "    # helper to normalize complex values (lists/dicts) to strings for grouping\n",
    "    def _norm_group(v):\n",
    "        if isinstance(v, (list, tuple, set)):\n",
    "            return ', '.join(map(str, v))\n",
    "        if isinstance(v, dict):\n",
    "            return json.dumps(v, sort_keys=True)\n",
    "        return v\n",
    "\n",
    "    # determine/normalize a usable grouping column\n",
    "    if preferred is None:\n",
    "        preferred = ['Disease', 'Tissue', 'Cell Type', 'Project', 'Batch', 'Sex', 'Age']\n",
    "    chosen = None\n",
    "    if group_by in plot_df.columns:\n",
    "        s = plot_df[group_by]\n",
    "        if np.issubdtype(s.dtype, np.number):\n",
    "            if s.nunique(dropna=True) >= 2:\n",
    "                chosen = group_by\n",
    "        else:\n",
    "            s2 = s.map(_norm_group)\n",
    "            if 2 <= s2.nunique(dropna=True) <= 10:\n",
    "                plot_df[group_by] = s2\n",
    "                chosen = group_by\n",
    "    # fallback: scan preferred list\n",
    "    if not chosen:\n",
    "        for c in preferred:\n",
    "            if c not in plot_df.columns:\n",
    "                continue\n",
    "            s = plot_df[c]\n",
    "            if np.issubdtype(s.dtype, np.number):\n",
    "                if s.nunique(dropna=True) >= 2:\n",
    "                    bname = f'{c}_binned'\n",
    "                    plot_df[bname] = pd.cut(\n",
    "                        s,\n",
    "                        bins=[-np.inf, 40, 50, 60, 70, 80, np.inf],\n",
    "                        labels=['<=40', '40-50', '50-60', '60-70', '70-80', '80+']\n",
    "                    )\n",
    "                    chosen = bname\n",
    "                    break\n",
    "            else:\n",
    "                s2 = s.map(_norm_group)\n",
    "                if 2 <= s2.nunique(dropna=True) <= 10:\n",
    "                    plot_df[c] = s2\n",
    "                    chosen = c\n",
    "                    break\n",
    "    group_by = chosen\n",
    "\n",
    "    # transform and ordering\n",
    "    if log1p:\n",
    "        y_col = 'log1p_value'\n",
    "        plot_df[y_col] = np.log1p(plot_df['value'])\n",
    "        ylabel = 'log1p(Expression)'\n",
    "        title = 'Expression of gene selection (log1p)'\n",
    "    else:\n",
    "        y_col = 'value'\n",
    "        ylabel = 'Expression'\n",
    "        title = 'Expression of gene selection'\n",
    "\n",
    "    order = (\n",
    "        plot_df.groupby('gene')['value']\n",
    "        .median()\n",
    "        .sort_values(ascending=False)\n",
    "        .index\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(max(min_figsize, figsize_scale * len(order)), height))\n",
    "    ax = sns.violinplot(\n",
    "        data=plot_df, x='gene', y=y_col, order=order,\n",
    "        hue=group_by, dodge=True, inner=None, cut=0, density_norm='width'\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=plot_df, x='gene', y=y_col, order=order,\n",
    "        hue=group_by, dodge=True, size=3, jitter=0.25, alpha=0.6,\n",
    "        linewidth=0, edgecolor=None\n",
    "    )\n",
    "    ax.set(xlabel='Gene', ylabel=ylabel, title=title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    # clean up duplicate legends from violin+strip\n",
    "    if group_by:\n",
    "        if ax.legend_:\n",
    "            ax.legend_.remove()\n",
    "        plt.legend(title=group_by, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    else:\n",
    "        if ax.legend_:\n",
    "            ax.legend_.remove()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_grouped_heatmap(\n",
    "    combined_data,\n",
    "    group_by=\"Disease\",\n",
    "    value_col='value',\n",
    "    gene_col='gene',\n",
    "    sample_col=\"genestack:accession\",\n",
    "    cmap='vlag',\n",
    "    log1p=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot enhanced grouped heatmap: genes as rows, samples as columns (optionally group columns/colors).\n",
    "    Shows gene names on the left side of the heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    combined_data : pd.DataFrame\n",
    "        DataFrame with gene expression data. Must contain gene_col, sample_col, value_col, and group_by.\n",
    "    group_by : str\n",
    "        Column to use for column color grouping (e.g., 'Disease').\n",
    "    value_col : str\n",
    "        Column with expression values.\n",
    "    gene_col : str\n",
    "        Column with gene names.\n",
    "    sample_col : str\n",
    "        Column with sample accessions.\n",
    "    cmap : str\n",
    "        Colormap to use for the heatmap.\n",
    "    log1p : bool\n",
    "        If True, log1p transform the expression values before visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    plot_df = combined_data.copy()\n",
    "\n",
    "    def _norm_group(v):\n",
    "        if isinstance(v, (list, tuple, set)):\n",
    "            return ', '.join(map(str, v))\n",
    "        if isinstance(v, dict):\n",
    "            return json.dumps(v, sort_keys=True)\n",
    "        return v\n",
    "\n",
    "    # pivot and normalize matrix: genes as rows, samples as columns\n",
    "    mat = plot_df.pivot_table(index=gene_col, columns=sample_col, values=value_col, aggfunc='median')\n",
    "\n",
    "    if log1p:\n",
    "        mat_proc = np.log1p(mat)\n",
    "    else:\n",
    "        mat_proc = mat\n",
    "\n",
    "    mat_z = (mat_proc - mat_proc.mean(axis=1).values[:, None]) / mat_proc.std(axis=1, ddof=0).values[:, None]\n",
    "    rows = mat_proc.median(axis=1).sort_values(ascending=False).index\n",
    "    mat_z = mat_z.loc[rows]\n",
    "\n",
    "    col_colors = None\n",
    "    legend_handles = None\n",
    "    palette = None\n",
    "\n",
    "    # column colors by group\n",
    "    if group_by and group_by in plot_df.columns:\n",
    "        plot_df[group_by] = plot_df[group_by].map(_norm_group)\n",
    "        meta = (\n",
    "            plot_df[[sample_col, group_by]]\n",
    "            .drop_duplicates().set_index(sample_col)\n",
    "            .reindex(mat_z.columns)\n",
    "        )\n",
    "        levels = meta[group_by].astype('category').cat.categories\n",
    "        palette = dict(zip(levels, sns.color_palette('Set2', n_colors=len(levels))))\n",
    "        col_colors = meta[group_by].map(palette)\n",
    "        mat_z = mat_z.loc[:, meta.sort_values(group_by).index]  # sort columns (samples) by group\n",
    "        # prepare legend handles\n",
    "        legend_handles = [\n",
    "            mpatches.Patch(color=palette[level], label=str(level)) for level in levels\n",
    "        ]\n",
    "\n",
    "    # create clustermap: genes as rows, samples as columns\n",
    "    g = sns.clustermap(\n",
    "        mat_z,\n",
    "        cmap=cmap,\n",
    "        center=0,\n",
    "        row_cluster=False,\n",
    "        col_cluster=False,\n",
    "        col_colors=col_colors,\n",
    "        cbar_kws={'label': 'Z-score (per gene)'},\n",
    "        figsize=(max(8, 0.22 * len(mat_z.columns)), max(8, 0.4 * len(rows))),\n",
    "        linewidths=0.1,\n",
    "        xticklabels=True,\n",
    "        yticklabels=True,\n",
    "        dendrogram_ratio=(.08, .02),  # row dendrogram larger, as genes are now rows\n",
    "        cbar_pos=(0.94, 0.7, 0.02, 0.18)\n",
    "    )\n",
    "    g.ax_heatmap.set_xlabel('Sample', fontsize=13, fontweight='bold')\n",
    "    g.ax_heatmap.set_ylabel('Gene', fontsize=13, fontweight='bold')\n",
    "    g.ax_heatmap.tick_params(axis='x', rotation=90, labelsize=10)\n",
    "    g.ax_heatmap.tick_params(axis='y', labelsize=10, labelleft=True, labelright=False)  # only show tick labels on the left\n",
    "\n",
    "    # add better title and annotation\n",
    "    if log1p:\n",
    "        title = f'Expression heatmap for gene selection\\n(log1p, per-gene z-score)'\n",
    "    else:\n",
    "        title = f'Expression heatmap for gene selection\\n(per-gene z-score)'\n",
    "    if group_by and group_by in plot_df.columns:\n",
    "        title += f'\\nGrouped by: {group_by}'\n",
    "    g.ax_heatmap.set_title(title, fontsize=15, fontweight='bold', pad=18)\n",
    "\n",
    "    # move cbar for better visibility\n",
    "    g.cax.set_position([.93, .18, .02, .55])\n",
    "\n",
    "    # show group (disease) legend at the top right of the plot, but do not show the title\n",
    "    if legend_handles is not None:\n",
    "        # place legend at top right of the figure, outside plot area\n",
    "        g.ax_heatmap.legend(\n",
    "            handles=legend_handles,\n",
    "            title=None,\n",
    "            loc='upper right',\n",
    "            bbox_to_anchor=(1.12, 1.01),  # (x, y) as fraction of axes; adjust as needed\n",
    "            borderaxespad=0.0,\n",
    "            fontsize='small',\n",
    "            frameon=False,\n",
    "            ncol=1\n",
    "        )\n",
    "\n",
    "    # show gene names on the left side only: hide any right-side y-tick labels\n",
    "    g.ax_heatmap.yaxis.tick_left()\n",
    "    g.ax_heatmap.yaxis.set_label_position(\"left\")\n",
    "    g.ax_heatmap.yaxis.set_ticks_position(\"left\")\n",
    "    g.ax_heatmap.tick_params(axis='y', which='both', labelleft=True, labelright=False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_correlation_scatter(data, title, method='pearson', color_by=None, width=None, height=None):\n",
    "    \"\"\"\n",
    "    Create a scatter plot with regression line and correlation statistics,\n",
    "    with optional color annotation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame with two numeric columns (e.g., 'transcript' and 'protein').\n",
    "    title : str\n",
    "        Title for the plot.\n",
    "    method : str, optional\n",
    "        Correlation method to use. Either 'pearson' or 'spearman' (default: 'pearson').\n",
    "    color_by : str, optional\n",
    "        Column name in `data` to color points by. May be numeric or categorical.\n",
    "    width : float, optional\n",
    "        Width of the figure in inches. If not provided, default figure size is used.\n",
    "    height : float, optional\n",
    "        Height of the figure in inches. If not provided, default figure size is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays the plot.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> import numpy as np\n",
    "    >>> df = pd.DataFrame({\n",
    "    ...     'transcript': np.random.randn(100),\n",
    "    ...     'protein': np.random.randn(100),\n",
    "    ...     'disease': np.random.choice(['NASH', 'Healthy'], size=100)\n",
    "    ... })\n",
    "    >>> plot_correlation_scatter(df, 'Gene_A', 'spearman', color_by='disease')\n",
    "    \"\"\"\n",
    "    # use first two numeric columns\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if len(numeric_cols) < 2:\n",
    "        raise ValueError(\"DataFrame must contain at least two numeric columns.\")\n",
    "    x_col = numeric_cols[0]\n",
    "    y_col = numeric_cols[1]\n",
    "\n",
    "    # extract data and remove NaN values (in x, y, and possibly color_by)\n",
    "    cols_to_check = [x_col, y_col]\n",
    "    if color_by is not None:\n",
    "        cols_to_check.append(color_by)\n",
    "    mask = ~data[cols_to_check].isna().any(axis=1)\n",
    "    clean_data = data.loc[mask]\n",
    "\n",
    "    x_clean = clean_data[x_col].values\n",
    "    y_clean = clean_data[y_col].values\n",
    "\n",
    "    if len(x_clean) < 3:\n",
    "        raise ValueError(\"Not enough valid data points (need at least 3) for correlation calculation.\")\n",
    "\n",
    "    # calculate correlation\n",
    "    if method.lower() == 'pearson':\n",
    "        corr_coef, p_value = pearsonr(x_clean, y_clean)\n",
    "    elif method.lower() == 'spearman':\n",
    "        corr_coef, p_value = spearmanr(x_clean, y_clean)\n",
    "    else:\n",
    "        raise ValueError(\"method must be either 'pearson' or 'spearman'.\")\n",
    "\n",
    "    # handle color_by logic\n",
    "    color_vals = None\n",
    "    color_legend_info = None\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    if color_by is not None and color_by in clean_data.columns:\n",
    "        color_data = clean_data[color_by]\n",
    "        if pd.api.types.is_numeric_dtype(color_data):\n",
    "            # Numeric, use colormap\n",
    "            cmap = plt.cm.viridis\n",
    "            color_vals = color_data.values\n",
    "            sc_kwargs = dict(c=color_vals, cmap=cmap)\n",
    "            color_legend_info = 'numeric'\n",
    "        else:\n",
    "            # Categorical\n",
    "            unique_cats = color_data.unique()\n",
    "            n_categories = len(unique_cats)\n",
    "            # Use tab10 or another colormap\n",
    "            cmap = plt.get_cmap('tab10') if n_categories <= 10 else plt.get_cmap('tab20')\n",
    "            color_map = {cat: cmap(i % cmap.N) for i, cat in enumerate(unique_cats)}\n",
    "            color_vals = color_data.map(color_map)\n",
    "            sc_kwargs = dict(c=color_vals)\n",
    "            color_legend_info = (unique_cats, color_map)\n",
    "    else:\n",
    "        sc_kwargs = {}\n",
    "\n",
    "    # create scatter plot with appropriate figure size and tight layout usage\n",
    "    if width is not None and height is not None:\n",
    "        plt.figure(figsize=(width, height))\n",
    "        use_tight_layout = False\n",
    "    else:\n",
    "        plt.figure()\n",
    "        use_tight_layout = True\n",
    "\n",
    "    ax = plt.gca()\n",
    "    scatter = plt.scatter(\n",
    "        x_clean,\n",
    "        y_clean,\n",
    "        alpha=0.7,\n",
    "        s=50,\n",
    "        **sc_kwargs\n",
    "    )\n",
    "\n",
    "    # add regression line\n",
    "    z = np.polyfit(x_clean, y_clean, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(x_clean.min(), x_clean.max(), 100)\n",
    "    plt.plot(x_line, p(x_line), \"r--\", alpha=0.8, linewidth=2, label='Regression line')\n",
    "\n",
    "    # add correlation statistics in top left corner\n",
    "    stats_text = f'r = {corr_coef:.3f}\\np = {p_value:.2e}'\n",
    "    plt.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "             fontsize=12, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "    # set labels and title\n",
    "    plt.xlabel(x_col, fontsize=12)\n",
    "    plt.ylabel(y_col, fontsize=12)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # add color legend/colorbar at right center if requested\n",
    "    if color_by is not None and color_by in clean_data.columns:\n",
    "        if color_legend_info == 'numeric':\n",
    "            cbar = plt.colorbar(scatter, ax=ax, fraction=0.05, pad=0.12)\n",
    "            cbar.set_label(color_by, fontsize=12)\n",
    "            cbar.ax.yaxis.set_ticks_position('right')\n",
    "            cbar.ax.yaxis.set_label_position('right')\n",
    "        else:\n",
    "            unique_cats, color_map = color_legend_info\n",
    "            handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor=color_map[cat],\n",
    "                              markersize=8, label=str(cat))\n",
    "                       for cat in unique_cats]\n",
    "            # Place legend at right center, outside plot\n",
    "            ax.legend(\n",
    "                handles=handles,\n",
    "                title=color_by,\n",
    "                loc='center left',\n",
    "                bbox_to_anchor=(1.03, 0.5),\n",
    "                borderaxespad=0.0,\n",
    "                fontsize='small',\n",
    "                frameon=False\n",
    "            )\n",
    "\n",
    "    if use_tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def map_protein_to_gene(protein_names, organism=\"Homo sapiens\"):\n",
    "    \"\"\"\n",
    "    Map protein names to human gene names using UniProt REST API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    protein_names : list\n",
    "        List of protein names to map (e.g., ['c-Met', 'Rictor', 'Paxillin']).\n",
    "    organism : str, optional\n",
    "        Organism filter for UniProt search (default: \"Homo sapiens\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping protein names to gene names.\n",
    "        If a protein name cannot be mapped, the value will be None.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> protein_names = ['c-Met', 'Rictor', 'Paxillin', 'p21']\n",
    "    >>> gene_mapping = map_protein_to_gene(protein_names)\n",
    "    >>> print(gene_mapping)\n",
    "    {'c-Met': 'MET', 'Rictor': 'RICTOR', 'Paxillin': 'PXN', 'p21': 'CDKN1A'}\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    base_url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "\n",
    "    for protein_name in protein_names:\n",
    "        # skip if already processed\n",
    "        if protein_name in mapping:\n",
    "            continue\n",
    "\n",
    "        # clean protein name for search (remove common suffixes/prefixes)\n",
    "        search_name = protein_name.strip()\n",
    "\n",
    "        # build query: search by protein name and organism\n",
    "        query = f'name:\"{search_name}\" AND organism:\"{organism}\"'\n",
    "        query = f\"protein_name:{search_name} AND organism_name:{organism} AND reviewed:true \"\n",
    "        params = {\n",
    "            'query': query,\n",
    "            'fields': 'gene_names',\n",
    "            'format': 'json',\n",
    "            'size': 1  # Only need first result\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # make API request\n",
    "            response = requests.get(base_url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            # extract gene name from response\n",
    "            gene_name = None\n",
    "            if data.get('results') and len(data['results']) > 0:\n",
    "                result = data['results'][0]\n",
    "                # try to get gene name from geneNames field\n",
    "                if 'genes' in result and len(result['genes']) > 0:\n",
    "                    gene_info = result['genes'][0]\n",
    "                    # prefer geneName over synonyms\n",
    "                    if 'geneName' in gene_info:\n",
    "                        gene_name = gene_info['geneName'].get('value')\n",
    "                    elif 'synonyms' in gene_info and len(gene_info['synonyms']) > 0:\n",
    "                        # fallback to first synonym if geneName not available\n",
    "                        gene_name = gene_info['synonyms'][0].get('value')\n",
    "\n",
    "            mapping[protein_name] = gene_name\n",
    "\n",
    "            # small delay to respect API rate limits\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # if API request fails, set to None\n",
    "            mapping[protein_name] = None\n",
    "            print(f\"Warning: Could not map '{protein_name}': {str(e)}\")\n",
    "        except (KeyError, IndexError) as e:\n",
    "            # if response structure is unexpected, set to None\n",
    "            mapping[protein_name] = None\n",
    "            print(f\"Warning: Unexpected response format for '{protein_name}': {str(e)}\")\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def compute_correlation_with_pvalue(df1, df2, axis=1, method='pearson'):\n",
    "    \"\"\"\n",
    "    Compute correlation coefficient and p-value between two dataframes or series.\n",
    "    Both df1 and df2 must have identical indexes and columns for axis=None.\n",
    "    For axis=0 or 1, computes correlation column-wise or row-wise.\n",
    "\n",
    "    Args:\n",
    "        df1, df2: pd.DataFrame or pd.Series\n",
    "        axis: If 0, computes correlation over rows for each column.\n",
    "              If 1, computes correlation over columns for each row.\n",
    "        method: If 'pearson', computes Pearson correlation.\n",
    "                If 'spearman', computes Spearman correlation.\n",
    "                Default is 'pearson'.\n",
    "    Returns:\n",
    "        pd.Series or pd.DataFrame: results with {'r': ..., 'p_value': ...}\n",
    "    \"\"\"\n",
    "    # determine which correlation function to use\n",
    "    if method == 'pearson':\n",
    "        corr_func = pearsonr\n",
    "        r_name = 'pearson_r'\n",
    "    elif method == 'spearman':\n",
    "        corr_func = spearmanr\n",
    "        r_name = 'spearman_r'\n",
    "    else:\n",
    "        raise ValueError(\"method must be either 'pearson' or 'spearman'.\")\n",
    "\n",
    "    if axis == 0:\n",
    "        # match columns, compute over rows for each column\n",
    "        if not all(df1.columns == df2.columns):\n",
    "            raise ValueError(\"Columns of the two dataframes are not identical.\")\n",
    "\n",
    "        corrs = []\n",
    "        for col in df1.columns:\n",
    "            x = df1[col]\n",
    "            y = df2[col]\n",
    "            mask = ~(pd.isna(x) | pd.isna(y))\n",
    "            if mask.sum() < 3:\n",
    "                corrs.append({r_name: np.nan, 'p_value': np.nan})\n",
    "            else:\n",
    "                corr, pval = corr_func(x[mask], y[mask])\n",
    "                corrs.append({r_name: corr, 'p_value': pval})\n",
    "        return pd.DataFrame(corrs, index=df1.columns)\n",
    "\n",
    "    elif axis == 1:\n",
    "        # match index, compute over columns for each row\n",
    "        if not df1.index.equals(df2.index):\n",
    "            raise ValueError(\"Indexes of the two dataframes are not identical.\")\n",
    "\n",
    "        corrs = []\n",
    "        for row in df1.index:\n",
    "            x = df1.loc[row, :]\n",
    "            y = df2.loc[row, :]\n",
    "            mask = ~(pd.isna(x) | pd.isna(y))\n",
    "            if mask.sum() < 3:\n",
    "                corrs.append({r_name: np.nan, 'p_value': np.nan})\n",
    "            else:\n",
    "                corr, pval = corr_func(x[mask], y[mask])\n",
    "                corrs.append({r_name: corr, 'p_value': pval})\n",
    "        return pd.DataFrame(corrs, index=df1.index)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"axis must be None, 0, or 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80914ee6",
   "metadata": {
    "id": "80914ee6"
   },
   "source": [
    "## 2. ODM API configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c126e9e",
   "metadata": {
    "id": "3c126e9e"
   },
   "source": [
    "**Configuring Access to Your ODM Instance**\n",
    "\n",
    "Before querying data, establish a connection to your ODM deployment and authenticate using an API token.  \n",
    "The ODM API uses token-based authentication, allowing secure programmatic access while preserving user-level permissions.\n",
    "\n",
    "In this section:\n",
    "* **Specify the ODM instance URL** – defines the environment you are connecting to.  \n",
    "* **Provide the API token** – identifies and authorizes your user session.  \n",
    "* **Initialize the ODM API client** – creates the communication layer for all subsequent requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db956b65",
   "metadata": {
    "id": "db956b65"
   },
   "outputs": [],
   "source": [
    "# input ODM server address\n",
    "server = 'https://q001-demo.trial.genestack.com/'\n",
    "\n",
    "# input API token\n",
    "set_api_credentials(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4853c",
   "metadata": {
    "id": "5cc4853c",
    "outputId": "72542b37-a85c-4c35-99cc-c3fe89bd1b7e"
   },
   "outputs": [],
   "source": [
    "# credentials sanity check\n",
    "if len(token)==0:\n",
    "    print(\"Failed to paste API token from clipboard! Set the token manually (e.g. via `token = 'your_token'`).\")\n",
    "else:\n",
    "    print(\"Token successfully set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3817be9",
   "metadata": {
    "id": "d3817be9",
    "outputId": "0dfdc290-bd75-4758-8ce6-2a0f03acaf56"
   },
   "outputs": [],
   "source": [
    "# initialize API client\n",
    "configuration = odm_api.Configuration(\n",
    "    host=server,\n",
    "    api_key={'Genestack-API-Token': token}\n",
    ")\n",
    "api_client = odm_api.ApiClient(configuration)\n",
    "\n",
    "# read odm-api documentation from\n",
    "print(f\"{server}/user-docs/tools/odm-api/python/generated/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d87405",
   "metadata": {
    "id": "90d87405"
   },
   "source": [
    "## 3. Working with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d81534",
   "metadata": {
    "id": "02d81534"
   },
   "source": [
    "### 3.1 Exploring Sample Endpoints\n",
    "\n",
    "In ODM, each entity—such as samples, datasets, or assays—can be accessed through dedicated API endpoints.\n",
    "The `Sample` class provides programmatic access to sample-level metadata, enabling you to search, retrieve, and inspect samples based on their attributes and values.\n",
    "\n",
    "In this step, the `Sample` interface is initialized, and its available methods are listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322021b6",
   "metadata": {
    "id": "322021b6",
    "outputId": "5721823f-ba95-46d8-b947-83ca2360b706"
   },
   "outputs": [],
   "source": [
    "# initialize API class\n",
    "sample_api = odm_api.SampleSPoTAsUserApi(api_client)\n",
    "\n",
    "# list all available sample_api endpoints\n",
    "for item in [item for item in dir(sample_api) if item.endswith(\"_as_user\")]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc46e1",
   "metadata": {
    "id": "afdc46e1"
   },
   "source": [
    "### 3.2 Searching for Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c5bfdf",
   "metadata": {
    "id": "d0c5bfdf"
   },
   "source": [
    "This section demonstrates how to retrieve sample metadata using the `search_samples_as_user` endpoint.\n",
    "The endpoint supports two complementary input parameters:\n",
    "\n",
    "* `query` — performs a full-text search across all metadata fields.\n",
    "\n",
    "* `filter` — applies logical conditions using metadata key–value pairs.\n",
    "\n",
    "Both can be combined in a single request for flexible data retrieval.\n",
    "The response includes:\n",
    "\n",
    "* `meta` – summary information about the search results.\n",
    "\n",
    "* `data` – a list of matching samples with their metadata attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af712a1",
   "metadata": {},
   "source": [
    "First, we will show how to retrieve a big number of samples for demonstration of `page_offset` parameter use when the number of samples is exceeding the `page_limit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search parameters\n",
    "sample_filter = 'Organism=\"Homo sapiens\"'\n",
    "\n",
    "# batch 1:retrieve first 2000 items from all the human samples query\n",
    "samples_batch1 = sample_api.search_samples_as_user(\n",
    "    filter=sample_filter,\n",
    "    page_limit=2000,\n",
    "    page_offset=0\n",
    ")\n",
    "\n",
    "# batch 2: retrieve the rest of the terms from all the human samples query\n",
    "# by setting 'page_offset' parameter equal to 'count' retrieved in 1st batch\n",
    "samples_batch2 = sample_api.search_samples_as_user(\n",
    "    filter=sample_filter,\n",
    "    page_limit=2000,\n",
    "    page_offset=1990\n",
    ")\n",
    "\n",
    "# show summary items from API responses\n",
    "print(json.dumps(samples_batch1.meta.to_dict(), indent=2))\n",
    "print(json.dumps(samples_batch2.meta.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae63b7d8",
   "metadata": {},
   "source": [
    "Next, we will use both sample query and filter parameters to retrieve and explore a specific list of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41a848",
   "metadata": {
    "id": "ee41a848",
    "outputId": "e49b3965-d317-4831-b3ea-bb821321fe21"
   },
   "outputs": [],
   "source": [
    "# define search parameters\n",
    "sample_query = 'steatohepatitis'\n",
    "sample_filter = 'Organism=\"Homo sapiens\" AND Tissue=\"liver\"'\n",
    "\n",
    "# search samples with both query and filter parameters\n",
    "samples = sample_api.search_samples_as_user(\n",
    "    filter=sample_filter,\n",
    "    query=sample_query\n",
    ")\n",
    "\n",
    "# show first items from API response\n",
    "print(json.dumps(samples.meta.to_dict(), indent=2))\n",
    "print(json.dumps(samples.data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4491a4",
   "metadata": {
    "id": "9a4491a4"
   },
   "source": [
    "### 3.3 Exploring Sample Metadata Summary\n",
    "\n",
    "This section summarizes the metadata attributes available in the retrieved sample set.\n",
    "The sample records returned by the API are converted into a DataFrame, and basic statistics are calculated to inspect attribute completeness and diversity.\n",
    "\n",
    "For each metadata field, the table shows:\n",
    "\n",
    "* `unique` – number of distinct values across all samples.\n",
    "\n",
    "* `total` – total number of samples included.\n",
    "\n",
    "* `top_values` – the most frequent attribute values observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343e721",
   "metadata": {
    "id": "f343e721",
    "outputId": "f7b0ab4a-a0f8-417d-a48e-22f3ace4bbef"
   },
   "outputs": [],
   "source": [
    "# convert samples.data list of dicts to a DataFrame\n",
    "samples_df = pd.DataFrame(samples.data).dropna(axis=1, how='all')\n",
    "\n",
    "# compute summary statistics for most common attribute values\n",
    "samples_summary = pd.DataFrame({\n",
    "    'unique': samples_df.nunique(),\n",
    "    'total': samples_df.shape[0],\n",
    "    'top_values': samples_df.apply(\n",
    "        lambda col: \" / \".join(col.value_counts(dropna=False).index.astype(str))\n",
    "    )\n",
    "})\n",
    "\n",
    "# show summary statistics\n",
    "samples_summary.sort_values('unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac7f60",
   "metadata": {
    "id": "44ac7f60"
   },
   "source": [
    "### 3.4 Exploring Integration Endpoints\n",
    "\n",
    "Unlike the previous sample endpoints that search for samples using their own attributes, integration endpoints allow you to find entities based on the attributes of related entities.\n",
    "In this example, studies can be retrieved by filtering on the attributes of samples that belong to them.\n",
    "\n",
    "The `StudyIntegrationApi` class provides methods for querying studies through their relationships with other entities such as samples, libraries, preparations, or files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0cb7c",
   "metadata": {
    "id": "d9a0cb7c",
    "outputId": "08910576-ec71-4f7b-f232-c76e1998946f"
   },
   "outputs": [],
   "source": [
    "# initialize API class\n",
    "study_integration_api = odm_api.StudyIntegrationAsUserApi(api_client)\n",
    "\n",
    "# list all available study_api endpoints\n",
    "for item in [item for item in dir(study_integration_api) if item.endswith(\"_as_user\")]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e09e0c",
   "metadata": {
    "id": "f4e09e0c"
   },
   "source": [
    "### 3.5 Retrieving Studies by Associated Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfdabdc",
   "metadata": {
    "id": "2cfdabdc"
   },
   "source": [
    "Integration endpoints allow identifying higher-level entities based on connected metadata objects.\n",
    "Here, the `get_studies_by_samples_as_user` integration endpoint is utilized to link and retrieve studies to samples, employing the identical sample filter as the preceding step. These integration endpoints are designed to identify higher-level entities by leveraging their connected metadata objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507eb576",
   "metadata": {
    "id": "507eb576",
    "outputId": "39dfccfe-1347-49c3-ed87-c03923a95a8e"
   },
   "outputs": [],
   "source": [
    "# define search parameters\n",
    "sample_query = 'steatohepatitis'\n",
    "sample_filter = 'Organism=\"Homo sapiens\" AND Tissue=\"liver\"'\n",
    "\n",
    "# search studies by sample groupId\n",
    "studies = study_integration_api.get_studies_by_samples_as_user(\n",
    "    filter=sample_filter,\n",
    "    query=sample_query\n",
    ")\n",
    "\n",
    "# show associated studies metadata\n",
    "studies_df = pd.DataFrame(studies.data).sort_values('genestack:accession')\n",
    "studies_df = studies_df.drop_duplicates(subset='Study Source ID', keep='first')\n",
    "studies_df = studies_df[~studies_df['Study Title'].str.contains('Test study')]\n",
    "studies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da6780",
   "metadata": {
    "id": "a0da6780"
   },
   "source": [
    "### 3.6 Exploring Omics Query Endpoints\n",
    "Omics query endpoints provide access to quantitative datasets such as gene expression, variant, or flow cytometry data, along with their associated metadata.\n",
    "These endpoints extend integration capabilities, enabling direct retrieval and filtering of omics measurements linked to specific samples or studies.\n",
    "\n",
    "In this step, the `OmicsQueries` interface is initialized, and its available methods are listed to illustrate the range of omics data types accessible through the ODM API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb24ab",
   "metadata": {
    "id": "13eb24ab",
    "outputId": "0fd36ced-39aa-4463-d641-33eba3c698ad"
   },
   "outputs": [],
   "source": [
    "# initialize API class\n",
    "omics_api = odm_api.OmicsQueriesAsUserApi(api_client)\n",
    "\n",
    "# list all available omics_api endpoints\n",
    "for item in [item for item in dir(omics_api) if item.endswith(\"_as_user\")]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53dc7a0",
   "metadata": {
    "id": "a53dc7a0"
   },
   "source": [
    "### 3.7 Searching Samples via Omics Query Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c12919",
   "metadata": {
    "id": "f7c12919"
   },
   "source": [
    "The `omics_search_samples_as_user` endpoint enables sample metadata search within the omics query interface.\n",
    "It functions similarly to the standard sample search but supports additional integration — combining study-level filters with sample attributes and linking downstream omics data types.\n",
    "\n",
    "The API response includes:\n",
    "\n",
    "* `log` – textual summary of matched studies and samples.\n",
    "\n",
    "* `data` – a list of metadata records for the retrieved samples.\n",
    "\n",
    "This combined search allows coordinated retrieval of samples and their related omics datasets across studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ac11d",
   "metadata": {
    "id": "f19ac11d",
    "outputId": "383ae1b4-945a-4422-a8f2-26d46bb6be95"
   },
   "outputs": [],
   "source": [
    "# define search parameters\n",
    "study_ids = studies_df[\"genestack:accession\"].tolist()\n",
    "study_filter = ' OR '.join([f'\"genestack:accession\"=\"{id}\"' for id in study_ids])\n",
    "sample_query = '\"steatohepatitis\" OR \"healthy\"'\n",
    "sample_filter = 'Organism=\"Homo sapiens\" AND Tissue=\"liver\"'\n",
    "\n",
    "# search samples with both study and sample query/filter parameters\n",
    "omics_samples = omics_api.omics_search_samples_as_user(\n",
    "    study_filter=study_filter,\n",
    "    sample_query=sample_query,\n",
    "    sample_filter=sample_filter,\n",
    "    returned_metadata_fields='original_data_included'\n",
    ")\n",
    "\n",
    "# show first items from API response\n",
    "print(json.dumps(omics_samples.log, indent=2))\n",
    "print(json.dumps(omics_samples.data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e86dd",
   "metadata": {
    "id": "4f8e86dd"
   },
   "source": [
    "### 3.8 Visualizing Sample Metadata Distributions\n",
    "\n",
    "This section illustrates how metadata attributes can be summarized and explored visually.\n",
    "By converting the retrieved sample metadata JSON into a structured DataFrame, we can examine the distribution of key attributes such as study group, disease state, and sex.\n",
    "\n",
    "The bar plots show how samples are distributed across these categories, enabling quick inspection of cohort balance and potential biases.\n",
    "Visualizing attribute frequencies at this stage helps verify that metadata relationships are consistent before performing downstream omics queries or expression analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a5fdb",
   "metadata": {
    "id": "ba5a5fdb",
    "outputId": "cadfe082-d2dd-4621-da9f-cd30990fd9f7"
   },
   "outputs": [],
   "source": [
    "# convert omics_samples.data list of nested dicts to a DataFrame\n",
    "omics_samples_df = pd.DataFrame([\n",
    "    item['metadata'] for item in omics_samples.data\n",
    "])\n",
    "omics_samples_df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# use disease abbreviation for visualization purposes\n",
    "omics_samples_df.loc[omics_samples_df['Disease'].eq(\n",
    "    \"metabolic dysfunction-associated steatohepatitis\"\n",
    "), 'Disease'] = 'NASH'\n",
    "\n",
    "# compute summary statistics for most common attribute values\n",
    "omics_samples_summary = pd.DataFrame({\n",
    "    'unique': omics_samples_df.nunique(),\n",
    "    'total': omics_samples_df.shape[0],\n",
    "    'top_values': omics_samples_df.apply(\n",
    "        lambda col: \" / \".join(col.value_counts(dropna=False).index.astype(str))\n",
    "    )\n",
    "})\n",
    "\n",
    "# show summary statistics\n",
    "omics_samples_summary.sort_values('unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1384f1",
   "metadata": {
    "id": "5b1384f1",
    "outputId": "dcc0aace-2cc9-483d-a4f8-bd5ef1097bde"
   },
   "outputs": [],
   "source": [
    "# plot frequencies for disease and groupId attributes\n",
    "group_counts = pd.crosstab(omics_samples_df['Disease'], omics_samples_df['groupId'])\n",
    "x = group_counts.plot(kind='barh', stacked=True, colormap='tab20', figsize=(5, 2))\n",
    "x.set_ylabel('')\n",
    "x.set_title(\"Sample count per disease, colored by groupId\")\n",
    "x.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()\n",
    "\n",
    "# plot frequencies for disease and sex attributes\n",
    "group_counts = pd.crosstab(omics_samples_df['Disease'], omics_samples_df['Sex'])\n",
    "x = group_counts.plot(kind='barh', stacked=True, colormap='tab20', figsize=(5, 2))\n",
    "x.set_ylabel('')\n",
    "x.set_title(\"Sample count per disease, colored by sex\")\n",
    "x.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8485cf4",
   "metadata": {
    "id": "d8485cf4"
   },
   "source": [
    "### 3.9 Retrieving Expression Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f291c4",
   "metadata": {
    "id": "f8f291c4"
   },
   "source": [
    "The `omics_search_expression_data_as_user` endpoint returns quantitative omics measurements with rich context.\n",
    "Here we query by feature (gene symbols) and restrict results by sample accessions.\n",
    "\n",
    "The response is a list of items; each item includes:\n",
    "\n",
    "* `itemOrigin` – provenance identifiers (e.g., run and group).\n",
    "\n",
    "* `metadata` – acquisition/processing details (platform, genome build, assay, files).\n",
    "\n",
    "* `feature` – the targeted feature (e.g., gene symbol).\n",
    "\n",
    "* `value` – the numeric measurement for that feature (representation depends on the dataset).\n",
    "\n",
    "* `relationships` – linked entities such as the sample accession.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe452f9",
   "metadata": {
    "id": "dbe452f9",
    "outputId": "722fde55-3e7d-4b2d-8bbd-e524b4280878"
   },
   "outputs": [],
   "source": [
    "# define search parameters\n",
    "genes = \"CD36, CPT1A, CYP7A1, NR1H4, HMGCR, LDLR, LRP1, PPARA, SCARB1, SQLE\"\n",
    "genes = re.sub(r'\\s+', '', genes)\n",
    "ex_query = f\"feature={genes}\"\n",
    "sample_ids = omics_samples_df[\"genestack:accession\"].tolist()\n",
    "sample_filter = ' OR '.join([f'\"genestack:accession\"=\"{id}\"' for id in sample_ids])\n",
    "\n",
    "# search expression data\n",
    "ex_data = omics_api.omics_search_expression_data_as_user(\n",
    "    ex_query=ex_query,\n",
    "    sample_filter=sample_filter\n",
    ")\n",
    "\n",
    "# show first data item from API response\n",
    "print(json.dumps(ex_data.data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473a708",
   "metadata": {
    "id": "7473a708"
   },
   "source": [
    "After retrieving expression data, the next step is to combine all response items into a unified DataFrame for inspection.\n",
    "Here, the metadata, feature, value, and relationship fields are merged, producing a tabular view of all expression records.\n",
    "\n",
    "The summary table shows:\n",
    "\n",
    "* `unique` – number of distinct values per attribute.\n",
    "\n",
    "* `total` – total number of expression records.\n",
    "\n",
    "* `top_values` – most common entries for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab570e",
   "metadata": {
    "id": "79ab570e",
    "outputId": "fcb9c998-87c0-4d07-e55a-c414aaaa592c"
   },
   "outputs": [],
   "source": [
    "# convert ex_data.data list of nested dicts to a DataFrame\n",
    "expression_df = pd.DataFrame([\n",
    "    item['metadata'] | item['feature'] | item['value'] | item['relationships']\n",
    "    for item in ex_data.data\n",
    "])\n",
    "expression_df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# compute summary statistics for most common attribute values\n",
    "ex_summary = pd.DataFrame({\n",
    "    'unique': expression_df.nunique(),\n",
    "    'total': expression_df.shape[0],\n",
    "    'top_values': expression_df.apply(\n",
    "        lambda col: \" / \".join(col.value_counts(dropna=False).index.astype(str))\n",
    "    )\n",
    "})\n",
    "\n",
    "# show summary statistics\n",
    "ex_summary.sort_values('unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12418b7",
   "metadata": {
    "id": "f12418b7"
   },
   "source": [
    "The expression data is coming from 2 sources with similar processing protocols and the reads mapped to the GRCh38 genome. This allows cross-study integration of the expression values for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc0088",
   "metadata": {
    "id": "8cfc0088"
   },
   "source": [
    "### 3.10 Visualizing Gene Expression Distributions\n",
    "\n",
    "Here, expression data are merged with sample metadata to enable joint visualization and context-aware interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad575ea",
   "metadata": {
    "id": "aad575ea"
   },
   "outputs": [],
   "source": [
    "# merge samples and expression data\n",
    "combined_data = pd.merge(\n",
    "    omics_samples_df,\n",
    "    expression_df,\n",
    "    left_on=\"genestack:accession\",\n",
    "    right_on=\"sample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f8e27",
   "metadata": {
    "id": "9a2f8e27"
   },
   "source": [
    "Boxplot of data distribution. Each box in the plot represents the distribution of expression values for one gene across all retrieved samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5363abb",
   "metadata": {
    "id": "a5363abb",
    "outputId": "723c619c-18ec-458d-a264-51cc27fc3500"
   },
   "outputs": [],
   "source": [
    "# plot expression values for each gene\n",
    "x = combined_data.boxplot('value', 'gene', rot=0, figsize=(7,4))\n",
    "x.set_title(\"Expression of genes\")\n",
    "x.set_xlabel('')\n",
    "plt.suptitle('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a20fe3",
   "metadata": {
    "id": "87a20fe3"
   },
   "source": [
    "This heatmap presents normalized expression profiles for the selected genes, grouped by a chosen metadata attribute.\n",
    "Here, expression values are transformed using a log1p scale and standardized as per-gene z-scores, allowing differences in relative expression levels to be compared across samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11438b49",
   "metadata": {
    "id": "11438b49",
    "outputId": "0e1e5d42-9d1f-43f8-d023-c21a845f6f44"
   },
   "outputs": [],
   "source": [
    "plot_grouped_heatmap(combined_data, group_by=\"Disease\", log1p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2205252",
   "metadata": {
    "id": "d2205252"
   },
   "source": [
    "### 3.11 Comparing Gene Expression Across Groups\n",
    "\n",
    "This plot visualizes the distribution of expression values for each gene, grouped by a categorical metadata attribute.\n",
    "\n",
    "Here, log1p-transformed expression levels are shown as violin plots, providing a combined view of data density and variability across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c8426",
   "metadata": {
    "id": "243c8426",
    "outputId": "932062ec-9429-4f30-b00d-fe25ee882006"
   },
   "outputs": [],
   "source": [
    "plot_grouped_violin(combined_data, group_by=\"Disease\", log1p=True, min_figsize=10, height=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b747663",
   "metadata": {
    "id": "0b747663"
   },
   "source": [
    "This plot shows expression distributions for each gene, grouped by a continuous metadata variable that has been binned into discrete intervals.\n",
    "\n",
    "Here, expression values remain on the original scale, allowing direct interpretation of magnitude differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a300b70",
   "metadata": {
    "id": "4a300b70",
    "outputId": "edcec0cc-a812-473f-8e9f-ba33c5faf045"
   },
   "outputs": [],
   "source": [
    "combined_data_filtered = combined_data.loc[combined_data[\"Disease\"].eq(\"NASH\")].copy()\n",
    "plot_grouped_violin(combined_data_filtered, group_by=\"Age\", log1p=False, min_figsize=10, height=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d617604",
   "metadata": {
    "id": "3d617604"
   },
   "source": [
    "### 3.12 Filtering Samples by Quantitative and Qualitative Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aaa55e",
   "metadata": {
    "id": "b3aaa55e"
   },
   "source": [
    "This example demonstrates how `omics_search_samples_as_user` can perform complex, multi-dimensional filtering across metadata and expression data.\n",
    "Unlike earlier queries limited to categorical metadata (e.g., organism or tissue), this query also introduces quantitative and omics-based conditions within a single search.\n",
    "\n",
    "Here, multiple query layers are combined:\n",
    "\n",
    "* Categorical filters define biological context (organism, tissue, or study).\n",
    "\n",
    "* Quantitative filters specify numeric constraints on metadata attributes (e.g., thresholds for age or concentration).\n",
    "\n",
    "* Expression filters restrict samples by quantitative omics measurements, such as a minimum expression value for a gene of interest.\n",
    "\n",
    "The API resolves these conditions in sequence, returning only samples that satisfy all specified filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513fbc0-4bbf-49ce-a719-0bbd1545ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search parameters\n",
    "sample_query = \"steatohepatitis\"\n",
    "sample_filter = 'Organism=\"Homo sapiens\" AND Tissue=\"liver\"'\n",
    "ex_query = 'feature=NR1H4 value >= 4'\n",
    "\n",
    "# search samples with both qualitative and quantitative query/filter parameters\n",
    "omics_samples = omics_api.omics_search_samples_as_user(\n",
    "    sample_query=sample_query,\n",
    "    sample_filter=sample_filter,\n",
    "    ex_query=ex_query\n",
    ")\n",
    "\n",
    "# show query\n",
    "print(json.dumps(omics_samples.log, indent=2))\n",
    "\n",
    "# extract sample ids\n",
    "sample_ids = [\n",
    "    item['metadata'].get('genestack:accession') for item in omics_samples.data\n",
    "]\n",
    "print(\"genestack:accession:\", sample_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5697fbb-6da6-410e-b363-ad8ef7e80b0b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Summary and Next Steps\n",
    "\n",
    "This notebook completes the preprocessing and analysis steps up to the integration of transcriptomics features and protein–gene mappings. The final multi-omics integration step (retrieval of matched transcriptomics expression data and downstream analyses) will be added once the transcriptomics expression group and API parameters are confirmed.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "32b59466"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
